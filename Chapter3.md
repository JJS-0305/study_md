# 저장소와 검색

- 데이터베이스가 데이터를 **저장하는 방법**과 데이터를 **요청 했을 때** 다시 찾을 수 있는 방법에 대해 설명
- 특정 작업부하(workload) 유형에서 좋은 성능을 내게끔 저장소 엔진을 조정하려면 저장소 엔진이 내부에서 수행되는 작업에 대해 대략적인 개념 이해 필요
- 관계형 데이터베이스와 NoSQL라 불리는 데이터베이스에 사용되는 저장소 엔진에 대해 설명
- **로그 구조(log-structured) 계열 저장소 엔진**과 B-tree 같은 **페이지 지향(page-oriented) 계열 저장소 엔진** 검토



## 데이터베이스를 강력하게 만드는 데이터 구조

많은 데이터베이스는 내부적으로 **추가 전용(append-only) 데이터 파일인 로그(log)** 를 사용한다. (이 책에서 로그는 조금 더 일반적인 의미로 연속된 추가 전용 레코드다.)
데이터베이스에서 특정 키의 값을 효율적으로 찾기 위해 등장한 데이터 구조가 **색인(index)** 이다.

- 색인을 잘 선택했다면 읽기 질의 속도가 향상된다.
- 모든 색인은 쓰기 속도를 떨어뜨린다.
  - 매번 색인도 갱신해야 하기 때문.
  - 이 때문에 데이터베이스는 보통 자동으로 모든것을 색인하지 않는다.


### 해시 색인

key-value 저장소

- 해시 맵(hash map)으로 구현.

가장 간단한 색인 전략

- 키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시 맵을 유지.

이 방법은 매우 단순해 보이지만 실제로 많이 사용하는 접근법.

- **램(RAM)에 모든 키가 저장된다는 조건**을 전제로 고성능 읽기, 쓰기 보장.
- 각 키의 값의 자주 갱신되는 상황에 매우 적합. (ex. key: 동영상 URL, value: 동영상 재생횟수)

파일에 항상 추가만 한다면 <u>디스크 공간 부족 발생.</u> 

***해결 방법?***

특정 크기의 segment로 로그 나누기

- 특정 크기에 도달하면 세그먼트 파일을 닫고 새로운 세그먼트 파일에 쓴다
- 세그먼트 파일에 대해 **컴팩션(compaction)**을 수행할 수 있다.
  - **컴팩션** : 로그에서 중복된 키를 버리고 각 키의 최신 갱신 값만 유지하는 것을 의미.
- 컴팩션을 하면 세그먼트가 작아지므로, 여러 세그먼트를 병합할 수 있다.
- 세그먼트는 절대 변경 불가 (append-only)
  - 병합할 세그먼트는 새로운 파일로 만든다.
  - 컴팩션을 수행하는 동안 이전 세그먼트 파일을 사용해 읽기와 쓰기요청을 처리한다.
  - 병합 과정이 끝난 이후에는 읽기 요청을 새로 병합한 세그먼트를 사용하게끔 전환한다.
  - 전환 후에는 이전 세그먼트 파일 삭제한다.

**조회**

- 최신 세그먼트 해시 맵에 찾으려는 키가 있는지 확인한다.
- 최신 세그먼트에 키가 없으면, 다음 세그먼트 해시 맵에서 키를 찾는다.

실제로 구현하려면 세부적으로 많은 사항 고려 필요.

- 파일 형식
- 레코드 삭제
- 고장(crash) 복구
- 부분적으로 레코드 쓰기
- 동시성 제어



**추가 전용 로그(append-only) 장점**

- **추가와 세그먼트 병합은 순차적인 쓰기 작업**이기 때문에 보통 무작위 쓰기보다 **훨씬 빠르다**.
  - 특히 자기 회전 디스크 하드드라이브에서 그렇다.
- 세그먼트 파일이 추가 전용이나 불변이면 **동시성과 고장복구는 훨씬 간단**하다.
  - 업데이트하는 동안 DB가 죽어도, 이전 값과 새로운 값 부분을 포함한 파일을 나누어 함께 남겨두기 때문.
- 오래된 세그먼트 병합은 시간이 지남에 따라 조각화되는 데이터 파일 문제를 피할 수 있다.



*제한 사항*

- 메모리에 저장해야 하므로 **키가 너무 많으면 문제 발생**.
  - 디스크에 해시 맵을 유지할 수 있지만, 디스크 상의 해시 맵에 좋은 성능을 기대하기란 어렵다.
  - 무작위 접근 I/O가 많이 필요.
  - 확장 비용이 비싸며 해시 충돌 해소를 위해 성가신 로직 필요

- 해시 테이블은 **범위 질의(range query)에 비효율적**.
  - 해시 맵에서 모든 개별 키를 조회해야한다.



### SS테이블과 LSM 트리

**Sorted String Table(SS테이블)**

- 세그먼트 파일에 Key-value 쌍을 key로 정렬하는 것
- 각 키는 각 병합된 세그먼트 파일 내에 한 번만 나타나야 한다.
  - 컴팩션 과정에서 이를 이미 보장한다.



해시 색인을 가진 로그 세그먼트에 비해 **SS테이블이 가지는 장점**

1. 세그먼트 병합은 파일이 사용 가능한 메모리보다 크더라도 간단하고 효율적
   - **병합정렬(merge sort)** 알고리즘과 유사함.
2. 파일에서 특정 키를 찾기 위해 더는 메모리에 **모든 키의 색인을 유지할 필요가 없음**.
   - 키의 정확한 오프셋을 알지 못해도 정렬되어 있으므로 두 키 사이에 있다는 사실을 알 수 있다.
   - 일부 키에 대한 오프셋을 알려주는 인메모리 색인이 여전히 필요하지만 희소하다.
3. 읽기 요청은 요청 범위 내에서 여러 key-value쌍을 스캔해야 하기 때문에 해당 레코드들을 블록으로 그룹화하고 디스크에 쓰기 전에 압축.
   - 희소 인메모리 색인의 각 항목은 압축된 블록의 시작을 가리키고, 디스크 공간 절약 및 I/O 대역폭 사용도 줄인다.



### SS테이블 생성과 유지

*데이터를 키에 정렬하려면?*

- 쓰기가 들어오면 인메모리 **균형 트리(balanced tree)** 데이터 구조에 추가.
  - 이 인메모리 트리를 **멤테이블(memtable)**이라고도 한다.
  - Ex. 레드 블랙 트리(red-black tree), AVL 트리 등
- 멤테이블이 임곗값보다 커지면 SS테이블 파일로 **디스크에 기록**.
  - 멤테이블은 이미 정렬되어 있으므로, SS테이블을 파일로 기록은 효율적.
  - 새로운 SS테이블 파일은 데이터베이스의 가장 최신 세그먼트가 된다.
  - SS테이블을 디스크에 기록하는동안 쓰기는 새로운 멤테이블 인스턴스에 기록한다.
- 읽기 요청이 들어오면 먼저 멤테이블에서 키를 찾는다.
  - 그 다음, 디스크 상의 가장 최신 세그먼트에서 찾는다.
  - 그 다음, 디스크 상의 두 번째 오래된(?) 세그먼트에서 찾는다.
  - 그 다음, 디스크 상의 세 번째 오래된 세그먼트에서 찾는다.
  - 그 다음, 디스크 상의 n 번째 오래된 세그먼트에서 찾는다.
- 세그먼트 병합과 컴팩션은 백그라운드에서 수행한다.
- 디스크로 기록되지 않은 **멤테이블 손실 방지**를 위해 **분리된 로그를 디스크에 유지**한다.
  - 멤테이블 복원 용으로만 필요하기 때문에 순서 정렬은 문제되지 않음.
  - 멤테이블을 SS테이블로 기록하고 나면 해당 로그는 버릴 수 있음.



### SS테이블에서 LSM 트리 만들기

*LSM 트리*

- 로그 구조화 병합 트리 (Log-Structured Merge-Tree)
- 정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라 부른다.
- 백그라운드에서 연쇄적으로 SS테이블을 지속적으로 병합하는 것.



### 성능 최적화

1. 블룸 필터(Bloom filter)
   - LSM 트리 알고리즘은 데이터베이스에 ***존재하지 않는 키를 찾는 경우*** 느릴 수 있다.
   - 멤테이블을 확인한 다음, 가장 오래된 세그먼트까지 찾아야 한다. (디스크에서 읽기를 해야 할 가능성)
   - 최적화하기 위해 **블룸 필터** 사용
     - 집합 내용을 근사한 메모리 효율적 데이터 구조
     - 키가 데이터베이스에 존재하지 않음을 알려주므로 존재하지 않는 키를 위한 불필요한 디스크 읽기 절약
2. 크기 계층 (size-tiered)과 레벨 컴팩션(leveled compaction)
   - SS테이블을 압축하고 병합하는 순서와 시기를 결정하는 전략
   - 사이즈 계층 컴팩션
     - 상대적으로 좀 **더 새롭고 작은 SS테이블**을 상대적으로 **오래됬고 큰 SS테이블에 연이어 병합**
   - 레벨 컴팩션
     - 키 범위를 더 작은 SS테이블로 나누고 오래된 데이터는 개별 레벨로 이동하기 때문에 컴팩션을 점진적으로 진행해 디스크 공간을 덜 사용.



데이터가 정렬된 순서로 저장돼 있다면 범위 질의를 효율적으로 실행할 수 있고, 디스크 쓰기는 순차적이기 때문에 LSM 트리가 매우 높은 쓰기 처리량 보장.



### B 트리

- 가장 널리 사용된는 색인 구조
  - 거의 대부분의 관계형 데이터베이스에서 표준 색인 구현으로 사용
  - 많은 비관계형 데이터베이스에서도 사용
- 키로 정렬된 key-value 쌍을 유지
  - Key-value 검색과 범위 질의에 효율적
  - LSM 트리와는 설계 철학이 다름.

B 트리

- 4KB 크기의 고정 크기 블록 배열
- 각 페이지는 주소나 위치를 이용해 식별 가능
- 하나의 페이지가 다른 페이지를 참조 가능
- 한 페이지는 B 트리의 루트로 지정
  -  키를 찾으면 루트에서 시작.

![그림3-6](/Users/jaesung.ju/Downloads/그림3-6.png)

- 검색(읽기)

![그림 3-7](/Users/jaesung.ju/Downloads/그림 3-7.png)

- 저장(쓰기)



B 트리에 존재하는 키 값 **갱신**

1. 키를 포함하고 있는 리프페이지 검색
2. 페이지의 값을 변경
3. 페이지를 디스크에 기록



B 트리에 새로운 키 **추가**

1. 새로운 키를 포함하는 범위의 페이지 찾기
2. 해당 범위의 페이지에 키와 값 추가
   - 페이지에 공간이 부족하다면, 페이지를 절반으로 쪼개고, 상위 페이지의 링크를 갱신
3. 이 알고리즘은 트리가 계속 **균형을 유지**하는 것을 보장.
   - n개의 키를 가진 B 트리는 깊이가 항상 *O(log n)*



### 신뢰할 수 있는 B 트리 만들기

- 새로운 데이터를 디스크 상의 페이지에 덮어쓰는 것으로 쓰기를함
  - 덮어쓰기기가 페이지 위치를 변경하지 않는다고 가정
  - 즉, 페이지가 덮어쓰더라도 페이지를 가르키는 모든 참조는 그대로 남음
- LSM 트리와 같은 로그 구조화 색인과는 대조되는 점
  - 로그 구조화 색인은 파일에 추가만 할 뿐 같은 위치의 파일은 변경하지 않음
- WAL(write-ahead alog == redo log == 재실행 로그)
  - 데이터베이스가 고장 상황에서 스스로 복구할 수 있게 하는 방법
  - 디스크 상에 쓰기 전 로그(WAL) 데이터 구조를 추가해 B트리 구현
- WAL은 트리 페이지에 변경된 내용을 적용하기 전에 모든 B트리의 변경사항을 기록하는 추가 전용 파일
  - 데이터베이스가 고장 이후 복구 될 때 일관성 있는 상태로 B트리 복구하는데 사용
- 동시성 제어
  - 같은 자리의 페이지를 갱신하는 작업시, 래치(latch - 가벼운 lock)로 트리의 데이터 구조를 보호함



### B 트리 최적화

- WAL 유지 대신 일부 데이터베이스는 'copy-on-write schema'을 사용
- 페이지에 전체 키를 저장하는 것이아닌 키를 축약해 공간 절약
- 리프 페이지를 디스크 상에 연속된 순서로 나타나게끔 트리를 배치하도록 시도
- 트리에 포인터 추가
- 프랙탈 트리



### B 트리와 LSM 트리 비교

- LSM 트리는 보통 쓰기에서 빠른 반면, B 트리는 읽기에서 빠름
  - LSM 트리에서 읽기가 느린 이유는 컴팩션 단계에 있는 여러 데이터 구조와 SS테이블을 확인해야하기 때문

### LSM 트리의 장점

- B트리 색인은 모든 데이터 조각을 최소한 두 번 기록해야함
  - wal 한번, 트리 페이지에 한번
  - 페이지 내 몇 바이트만 바껴도 한번에 전체 페이지를 기록해야하는 오버헤드가 있음
- 로그 구조화 색인 또한 SS테이블의 반복된 컴팩션과 병합으로 인해 여러번 데이터를 다시 씀
  - 데이터베이스에 쓰기 한번이 데이터베이스 수명 동안 디스크에 여러번의 쓰기를 야기하는 효과를 **쓰기 증폭(write amplification)** 이라고 한다.
  - SSD는 수명이 다할 때까지 블록덮어쓰기 횟수가 제한되기 때문에 쓰기 증폭은 SSD 경우 특별한 관심사라고함
- LSM 트리는 B 트리보다 쓰기 처리량을 높게 유지할 수 있음
  - 상대적으로 쓰기 증폭이 더 낮고 트리에서 여러 페이지를 덮어쓰는 것이 아니라, 순차적 컴팩션된 SS테이블 파일 쓰기 때문
  - 이는 HDD의 순차쓰기가 랜덤쓰기보다 빠른 점에서 유용한 장점이 될 수 있음
- 압축률이 더 좋음
  - B 트리는 파편화로 사용하지 않은 디스크 공간이 있음
  - 페이지를 나누거나 로우가 기존 페이지에 맞지 않을 때 페이지 일부 공간을 사용하지 않음
  - 하지만, LSM은 주기적으로 파편화를 없애기 위해 SS테이블을 다시 기록하기 때문에 저장소 오버헤드가 낮음

### LSM 트리의 단점

- 컴팩션 과정이 때로는 진행중인 읽기와 쓰기의 성능에 영향을 줌
  - 저장소 엔진은 컴팩션을 점진적으로 수행하고 동시 접근의 영향이 없게 수행하려함
  - 하지만 디스크가 가진 자원의 한계로 비싼 컴팩션 연산이 끝날 때까지 요청이 대기애햐하는 상황이 발생함
- 디스크 쓰기 대역폭의 한계
  - 디스크 쓰기 대역폭은 유한하고, 초기에 로깅,멤테이블을 디스크로 flush하는 것과 백그라운드에서 수행하는 컴팩션 스레드는 이 대역폭을 공유
  - 빈 데이터베이스는 전체 디스크 대역폭을 초기 쓰기만을 위해 사용할 수 있지만, 커질수록 컴팩션을 위해 더 많은 디스크 대역폭이 필요함
- 컴팩션이 늦어져 디스크 공간 부족해질 수 있음
- B트리의 장점은 각 키가 색인의 한곳에만 정확하게 있다는 점
- 반면, 로그 구조화 저장소 엔진은 다른 세크먼트에 같은 키의 다중 복사본이 존재할 수 있음
  - 강력한 트랙잭션이 요구되는 상황에서는 B트리가 더 유용함



### 기타 색인 구조

- 키-값 색인의 대표적인 예로는 관계형 모델의 기본키 색인이다.
- **보조 색인**을 사용하는 방법도 매우 일반적이다.
  - 관계형 데이터베이스에서 “CREATE INDEX” 명령을 통해 같은 테이블에 다양한 보조색인을 생성하는 방법
  - 보통 효율적으로 조인을 수행하는 데 결정적인 역할을 한다.
  - 기본키 색인과의 차이점은 키가 고유하지 않다는 점
    - 색인의 각 값에 일치하는 로우 식별자 목록을 만드는 방법
    - 로우 식별자를 추가해 각 키를 고유하게 만드는 방법



### 색인 안에 값 저장하기

- 힙 파일 접근 방식
  - 다른 곳에 지정된 로우를 가리키는 경우 로우가 저장된 곳을 힙 파일 이라 하고 특정 순서 없이 데이터를 저장 한다.
  - 여러 보조 색인이 존재할 때 데이터 중복을 피할 수 있다.
  - 키를 변경하지 않고 값을 갱신 할 때 꽤 효율적이다.
- **클러스터드 색인**
  - 색인에서 힙 파일로 다시 이동하는 일은 읽기 성능에 불이익이 너무 많아서 특정 상황에서는 색인된 로우를 바로 저장하는 편이 바람직한데, 이를 클러스터드 색인이라 한다.
  - ex)  Mysql 의 InnoDB 저장소 엔진에서는 테이블의 기본키가 언제나 클러스터드 색인이고 보조 색인은 기본키를 참조 한다.
- 클러스터드 색인과 비클러스터드 (색인 안에 참조만 저장) 사이의 절충안을 **커버링 색인(covering index) 이나 포괄 열이 있는 색인(index with included column)** 이라 한다.
  - 색인 안에 테이블의 컬럼 일부를 저장함, 이렇게 할 경우 색인만 사용해 일부 질의에 응답이 가능.
- 클러스터드 색인과 커버링 색인은 읽기 성능을 높일 수 있지만 복제로 인한 불일치를 파악할 수 없으므로 트랜잭션 보장 강화를 위한 별도의 노력이 필요하다.

### 다중 컬럼 색인

- 가장 일반적인 유형은 **결합 색인 (concatenated index)** 이라고 한다.
  - 하나의 컬럼에 다른 컬럼을 추가하는 방식, 하나의 키에 여러 필드를 단순히 결합 한다.
- 다차원 색인은 보통 지리 공간 데이터에서 중요하게 사용 된다.
  - ex) R 트리처럼 전문 공간 색인을 사용한 PostGIS
- 하지만 지리하적인 위치에만 국한되지는 않는다. 날씨 관측 데이터베이스에서 (날짜,기온)의 2차원 색인을 사용할 수도 있음



## 트랜잭션 처리나 분석?

*온라인 트랜잭션 처리 (online transaction processing, **OLTP**)*

- 색인을 사용해 적은 수의 레코드를 찾는다.
- 레코드는 사용자 입력을 기반으로 삽입 or 갱신된다. (대화식 접근 패턴)

*온라인 분석 처리 (online analytic processing, **OLAP**)*

- 원시 데이터를 반환하는 것이 아니라 많은 수의 레코드를 스캔해 집계 통계를 계산
- 비즈니스 분석가가 작성하며 회사 경영진이 더 나은 의사결정을 하게끔 돕는 보고서를 제공
  - **비즈니스 인텔리전스(business intelligence)** 라고 함.



OLTP와 OLAP 전형적인 특성 비교

| 특성           | OLTP                                            | OLAP                                              |
| -------------- | ----------------------------------------------- | ------------------------------------------------- |
| 주요 읽기 패턴 | 질의당 적은 수의 레코드, 키 기준                | 많은 레코드에 대한 집계                           |
| 주요 쓰기 패턴 | 임의 접근, 사용자 입력을 낮은 지연시간으로 기록 | 대규모 불러오기(bulk,import..) 또는 이벤트 스트림 |
| 주요 사용처    | 웹 애플리케이션을 통한 사용자/소비자            | 의사결정 지원을 위한 내부 분석가                  |
| 데이터 표현    | 데이터의 최신상태 (현재 시점)                   | 시간이 지나며 일어난 이력                         |
| 데이터셋 크기  | 기가바이트에서 테라바이트                       | 테라바이트에서 페타바이트                         |

- 1980년대 후반과 1990년대 초반, 회사들은 OLTP 시스템을 분석 목적으로 사용하지 않고 개별 데이터베스에서 분석을 수행했는데, 이를 **데이터 웨어하우스**라고 불렀다.



### 데이터 웨어하우징

- 분석가들이 OLTP 작업에 영향을 주지 않고 마음껏 질의할 수 있는 개별 데이터베이스
- 다양한 OLTP 시스템에 있는 데이터의 읽기 전용 복사본
- OLTP 데이터베이스에서 주기적인 데이터 덤프나 지속적인 갱신 스트림을 사용해 데이터 웨어하우스에 적재함.
  - 데이터 웨어하우스로 데이터를 가져오는 이 과정을 **ETL(Extract-Transform-Load)** 라고 한다.

- 분석 접근 패턴에 맞게 최적화할 수 있다는 장점



### OLTP 데이터베이스와 데이터 웨어하우스의 차이점

- 둘 다 SQL 질의 인터페이스를 지원하기 때문에 비슷해 보임.
- 하지만 각각 매우 다른 질의 패턴에 맞게 최적화되어 시스템 내부는 완전히 다름.
- 데이터베이스 벤더는 트랜잭션 처리와 분석 작업부하 양쪽 모두를 지원하기보다 둘 중 하나를 지원하는데 중점.
- 데이터 웨어하우스 벤더는 보통 값비싼 상용 라이선스로 시스템을 판매
  - 다수의 오픈소스 **SQL 온 하둡 (SQL-on-Hadoop)** 프로젝트들이 상용 라이선스와 경쟁을 목표로 생겨남.



### 분석용 스키마: 별 모양 스키마와 눈꽃송이 모양 스키마

- 많은 데이터 웨어하우스는 **별모양 스키마(star schema)** 로 알려진 상당히 정형화된 방식을 사용한다.
  - **차원 모델링(dimensional modeling)**이라고도 함

[그림 3-9]

- 스키마 중심에 소위 **사실 테이블 (fact table)**이 있다.
  - 예제에서는 fact-scales라고 함
  - 다른 칼럼은 **차원 테이블(dimension table)** 이라 부르는 다른 테이블을 가리키는 왜래 키 참조
    - 차원은 이벤트 속성을 나타냄
      - 누가(who), 언제(when), 어디서(where), 무엇을(what), 어떻게(how), 왜(why)
- 별 모양 스키마
  - 사실 테이블이 가운데에 있고, 차원 테이블이 둘러싸고 있다는 사실에서 비롯
- 눈꽃송이 모양 스키마(snowflake schema)
  - 별 모양 스키마의 변형으로 차원 테이블이 하위 차원으로 더 세분화
- 분석가들은 더 작업하기 쉽다는 이유로 별 모양 스키마를 선호.



### 칼럼 지향 저장소

- OLTP 데이터베이스
  - **로우 지향 방식**으로 데이터를 배치
  - 테이블의 한 로우의 모든 값은 서로 인접하게 저장됨.
- 칼럼 지향 저장소
  - 모든 값을 하나의 로우에 함께 저장하지 않는 대신 **각 칼럼별로 모든 값을 함께 저장**.
  - 각 칼럼을 개별 파일에 저장하면 **질의에 사용되는 칼럼만** 읽고 분석할 수 있음.

[그림 3-10]

- 각 칼럼 파일에 포함된 로우가 모두 **같은 순서**인 점에 의존



### 칼럼 압축

- 질의에 필요한 칼럼을 디스크에서 읽어 적재하는 작업 외에도 **데이터를 압축**하면 디스크 처리량을 더 줄일 수 있다.
  - 칼럼 지향 저장소는 대게 압축에 적합함
- 다양한 압축 기법 사용할 수 있지만 데이터 웨어하우스에서 **비트맵 부호화(bitmap encoding)** 이 특히 효과적

[그림 3-11]

- 칼럼값의 고유값으로 0,1로 변환하고,  0값이 많은 희소한 상황에서는 *런 렝스 부호화* 할 수 있다.
  - 칼럼의 부호화를 현저히 줄임.

### 칼럼 저장소의 순서 정렬

- 삽입된 순서로 저장하는 방식이 가장 쉽다.
- 이전 SS테이블에서 했던 것처럼 순서를 도입해 이를 색인 메커니즘으로 사용할 수 있다
  - 각 칼럼을 독립적으로 정렬할 수는 없다. (데이터는 한번에 전체 로우를 정렬해야 함)
- 정렬된 순서의 또 다른 장점은 컬럼 압축에 도움이 된다.



### 다양한 순서 정렬

- 같은 데이터를 **다양한 방식**으로 정렬해 저장한다면?
  - 하나의 장비가 고장나도 데이터 손실을 방지하려면 여러 장비에 복제해 두는 작업이 필요.
    - 복제 데이터를 서로 다른 방식으로 정렬해서 저장하면, 질의 패턴에 가장 적합한 버전 사용 가능
- 로우 지향 저장에서 2차 색인을 갖는것과 약간은 비슷
  - 칼럼 저장방식에서는 데이터를 가리키는 포인터는 없고, 값을 포함한 칼럼만 존재한다.



### 집계: 데이터 큐브와 구체화 뷰

- 앞서 설명한 데이터 웨어하우스 질의는 보통 집계 함수를 포함한다. (SUM, MAX ,COUNT ...)
- 질의가 자주 사용하는 일부 count 나 sum 을 캐시하는건 어떨까?
  - **구체화 뷰(materialized view)**
    - 관계형 데이터 모델에서는 이런 캐시를 대게 표준(가상) 뷰로 정의 한다.
    - 표준(가상) 뷰와 구체화 뷰의 차이점은 구체화 뷰는 디스크에 기록된 질의 결과의 실제 복사본이지만, 표준 뷰는 그저 질의를 하기 위한 단축키일 뿐이다. 
    - 원본 데이터가 변경되면 구체화 뷰는 갱신해야 한다.
      - 이런 갱신으로 인한 쓰기 비용은 비싸기 때문에 OLTP 데이터베이스 에서는 구체화 뷰를 자주 사용하진 않는다.
      - 데이터 웨어하우스는 읽기 비중이 크기 때문에 구체화 뷰 사용이 합리적인 것.
  - **데이터 큐브 (OLAP 큐브)**
    - 일반화된 구체화 뷰의 특별 사례 케이스
    - 특정 질의를 효과적으로 미리 계산했기 때문에 해당 질의를 수행할 때 매우 빠르다는 장점이 있다.
    - 원시 데이터에 질의하는 것과 동일한 유연성이 없다는 것이 단점.
      - 데이터 웨어하우스는 가능한 한 많은 원시 데이터를 유지하려고 노력.
      - 데이터 큐느와 같은 집계 값은 특정 질의에 대한 성능 향상에만 사용.

